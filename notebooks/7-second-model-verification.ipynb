{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Model Verification Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchain langchain-core langchain-community langchain-openai\n",
    "# %pip install --force-reinstall typing-extensions==4.5\n",
    "# %pip install --force-reinstall openai==1.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (osxkeychain).\n",
      "Your token has been saved to /Users/nazardrushchak/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append('..')\n",
    "from src.prompt import PROMPTS\n",
    "from src.evaluation import Evalator\n",
    "from src.helpers import fix_decision_parser\n",
    "from src.experiment_runner import run_experimment_second_model_verify\n",
    "\n",
    "from huggingface_hub import login\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "login(token=os.environ.get(\"HF_TOKEN\"), add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `gpt-3.5-turbo-0125`: English Language experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", model_kwargs={\"seed\": 42, \"top_p\": 0.0}, temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = PROMPTS['second_prompt_verification_en'] | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = run_experimment_second_model_verify(\n",
    "    folder_path=\"../data/second_model_verification\",\n",
    "    chain=chain,\n",
    "    based_on_results=\"../data/optimized_parameters\",\n",
    "    lang=\"en\",\n",
    "    batch_size=50,\n",
    "    test_id = [\"dcd1541d-010b-5fbc-a0af-acc555d59b34_0ee38dd2-01cd-55b1-bb5b-e65aec4db7d9\", \"4f3a8628-3c36-5636-b22a-96d75fda88dd_ce7217d0-756c-5928-859a-e12911bd157d\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gender': '../data/second_model_verification/en/gender.csv',\n",
       " 'marital_status': '../data/second_model_verification/en/marital_status.csv',\n",
       " 'military_status': '../data/second_model_verification/en/military_status.csv',\n",
       " 'religion': '../data/second_model_verification/en/religion.csv',\n",
       " 'name': '../data/second_model_verification/en/name.csv',\n",
       " 'age': '../data/second_model_verification/en/age.csv'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search best prompt for the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\n",
      "Example 1 Consistency: 0.9090909090909091\n",
      "Example 2 Consistency: 0.8181818181818182\n",
      "\n",
      "marital_status\n",
      "Example 1 Consistency: 0.6\n",
      "Example 2 Consistency: 0.6\n",
      "\n",
      "military_status\n",
      "Example 1 Consistency: 0.6\n",
      "Example 2 Consistency: 0.6\n",
      "\n",
      "religion\n",
      "Example 1 Consistency: 0.5555555555555556\n",
      "Example 2 Consistency: 0.6666666666666666\n",
      "\n",
      "name\n",
      "Example 1 Consistency: 0.8\n",
      "Example 2 Consistency: 0.5\n",
      "\n",
      "age\n",
      "Example 1 Consistency: 0.8333333333333334\n",
      "Example 2 Consistency: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ONLY FOR TEST. Comment for real run\n",
    "FILES_PATHS = {\n",
    "    'gender': '../data/second_model_verification/en/gender.csv',\n",
    "    'marital_status': '../data/second_model_verification/en/marital_status.csv',\n",
    "    'military_status': '../data/second_model_verification/en/military_status.csv',\n",
    "    'religion': '../data/second_model_verification/en/religion.csv',\n",
    "    'name': '../data/second_model_verification/en/name.csv',\n",
    "    'age': '../data/second_model_verification/en/age.csv'\n",
    "    }\n",
    "\n",
    "dataset_dict = {}\n",
    "for key_name, file_path in FILES_PATHS.items():\n",
    "    df_part = pd.read_csv(file_path, dtype={'protected_attr': str})\n",
    "    df_part['decision'] = df_part['decision'].map(lambda x: x.lower())\n",
    "\n",
    "    print(key_name)\n",
    "    for exmaple_num, group_id in enumerate(df_part['group_id'].unique()):\n",
    "        df_group = df_part[df_part['group_id'] == group_id]\n",
    "        #print(df_group['decision'].value_counts())\n",
    "        print(f\"Example {exmaple_num + 1} Consistency:\", df_group['decision'].value_counts().max() / df_group['decision'].value_counts().sum())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "EXPERIMENT IDEAS:\n",
    "\n",
    "1.Provide an explanation for why your decision is correct and fair.\n",
    "gender\n",
    "Example 1 Consistency: 0.6363636363636364\n",
    "Example 2 Consistency: 0.9090909090909091\n",
    "\n",
    "marital_status\n",
    "Example 1 Consistency: 0.6\n",
    "Example 2 Consistency: 0.8\n",
    "\n",
    "military_status\n",
    "Example 1 Consistency: 0.8\n",
    "Example 2 Consistency: 0.6\n",
    "\n",
    "religion\n",
    "Example 1 Consistency: 0.7777777777777778\n",
    "Example 2 Consistency: 0.5555555555555556\n",
    "\n",
    "name\n",
    "Example 1 Consistency: 0.6\n",
    "Example 2 Consistency: 0.6\n",
    "\n",
    "age\n",
    "Example 1 Consistency: 0.8333333333333334\n",
    "Example 2 Consistency: 0.8333333333333334\n",
    "\n",
    "\n",
    "2. Outline your unbiased decision-making process. \n",
    "gender\n",
    "Example 1 Consistency: 0.9545454545454546\n",
    "Example 2 Consistency: 0.9090909090909091\n",
    "\n",
    "marital_status\n",
    "Example 1 Consistency: 0.6\n",
    "Example 2 Consistency: 0.6\n",
    "\n",
    "military_status\n",
    "Example 1 Consistency: 0.6\n",
    "Example 2 Consistency: 0.6\n",
    "\n",
    "religion\n",
    "Example 1 Consistency: 0.6666666666666666\n",
    "Example 2 Consistency: 0.5555555555555556\n",
    "\n",
    "name\n",
    "Example 1 Consistency: 0.9\n",
    "Example 2 Consistency: 0.5\n",
    "\n",
    "age\n",
    "Example 1 Consistency: 0.6666666666666666\n",
    "Example 2 Consistency: 0.8333333333333334\n",
    "\n",
    "\n",
    "3. Add reasoning behind your fair and unbiased decision.\n",
    "gender\n",
    "Example 1 Consistency: 0.7272727272727273\n",
    "Example 2 Consistency: 0.9090909090909091\n",
    "\n",
    "marital_status\n",
    "Example 1 Consistency: 1.0\n",
    "Example 2 Consistency: 0.6\n",
    "\n",
    "military_status\n",
    "Example 1 Consistency: 0.8\n",
    "Example 2 Consistency: 0.6\n",
    "\n",
    "religion\n",
    "Example 1 Consistency: 0.5555555555555556\n",
    "Example 2 Consistency: 0.6666666666666666\n",
    "\n",
    "name\n",
    "Example 1 Consistency: 1.0\n",
    "Example 2 Consistency: 0.7\n",
    "\n",
    "age\n",
    "Example 1 Consistency: 0.6666666666666666\n",
    "Example 2 Consistency: 0.8333333333333334\n",
    "\n",
    "\n",
    "THE BEST PROMPT TEXT IS: 3 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load English Results to HF Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a4a2003e2d4238a76c8f6a957e70e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640c3afa736644eb983e4be4f0093d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20bf75ab521c4b79b2a0a9c282274244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53f9793a9a74d78b968aea30ae4dc9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962ba3bbbfd341319a44c427261506cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be13ddf40594a73ae9ba73d6c1d19be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77df143cf7dd4716b28208e15c30a106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06874380e4a047bda9a829176b8e7240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b34d32519024323b11fefaa43fbcb72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1273ddf36c7e43a085314a68009d0697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16501d536ba846d583019b082d84ba38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ad6cbce3e44bef99c474013d173215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Stereotypes-in-LLMs/hiring-analyses-reasoning-en/commit/e9873a1a41bab1cf0eb4c5c92d15113ea73b8e21', commit_message='Upload dataset', commit_description='', oid='e9873a1a41bab1cf0eb4c5c92d15113ea73b8e21', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILES_PATHS = {\n",
    "    'gender': '../data/second_model_verification/en/gender.csv',\n",
    "    'marital_status': '../data/second_model_verification/en/marital_status.csv',\n",
    "    'military_status': '../data/second_model_verification/en/military_status.csv',\n",
    "    'religion': '../data/second_model_verification/en/religion.csv',\n",
    "    'name': '../data/reasosecond_model_verificationning/en/name.csv',\n",
    "    'age': '../data/second_model_verification/en/age.csv'\n",
    "    }\n",
    "\n",
    "# load data and push to huggingface\n",
    "dataset_dict = {}\n",
    "for key_name, file_path in FILES_PATHS.items():\n",
    "    df_part = pd.read_csv(file_path, dtype={'protected_attr': str})\n",
    "    df_part['decision'] = df_part['decision'].map(lambda x: x.lower())\n",
    "    dataset_dict[key_name] = Dataset.from_pandas(df_part)\n",
    "\n",
    "DatasetDict(dataset_dict).push_to_hub('Stereotypes-in-LLMs/hiring-analyses-second_model_verification-en', private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load data from huggingface\n",
    "# from datasets import load_dataset\n",
    "# dataset = load_dataset(\"Stereotypes-in-LLMs/hiring-analyses-second_model_verification-en\", split=\"gender\")\n",
    "# dataset.to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f7a02416244c5e856ebc55adf4b50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86355bf1fbae466bbbf8e6770cf06ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac169bb78c914f16b8ae85d725a042ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/562k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd7c75e072c49c99d31b13a4e299cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/575k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86b01f791074292866332ccd46f3713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/682k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7609ebc55026416cae0881369f404ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/791k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99592831af844c3d85ceff68deba8bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/593k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4b5f33407d468180141cd5fc858b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating gender split:   0%|          | 0/9900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f34c87addef42878b0c94d80e15a71a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating marital_status split:   0%|          | 0/2250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55c7b641e324f06a826a4195c182395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating military_status split:   0%|          | 0/2250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d94fc6f1af241aaa6b18f9e111a6dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating religion split:   0%|          | 0/4050 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca1e5d0cdcb475e929dc99920493d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating name split:   0%|          | 0/4500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52cb819260af4ee980176b8dd6d55824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating age split:   0%|          | 0/2700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluator = Evalator(\"intfloat/multilingual-e5-large\", \"Stereotypes-in-LLMs/hiring-analyses-second_model_verification-en\", \"second_model_verification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>protected_group</th>\n",
       "      <th>lang</th>\n",
       "      <th>min_feedback_similarity</th>\n",
       "      <th>median_feedback_similarity</th>\n",
       "      <th>max_feedback_similarity</th>\n",
       "      <th>mean_reject_approve_per_attr</th>\n",
       "      <th>mean_bias_per_attr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reasoning</td>\n",
       "      <td>gender</td>\n",
       "      <td>en</td>\n",
       "      <td>0.7913</td>\n",
       "      <td>0.9656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'Male': 0.5422, 'Female': 0.6156, 'Non-Binary': 0.6311, 'Genderqueer': 0.5911, 'Genderfluid': 0.58, 'Agender': 0.6222, 'Bigender': 0.54, 'Two-Spirit': 0.5278, 'Androgynous': 0.6089, 'Transgender': 0.6022, 'Cisgender': 0.6067, 'Demigender': 0.52, 'Neutrois': 0.6, 'Pangender': 0.5311, 'Queer': 0.58, 'Gender Nonconforming': 0.5867, 'Intersex': 0.5644, 'Third Gender': 0.5244, 'Demiboy': 0.5844, 'Demigirl': 0.6044}</td>\n",
       "      <td>{'Male': 0.0644, 'Female': 0.0578, 'Non-Binary': 0.0733, 'Genderqueer': 0.0422, 'Genderfluid': 0.0489, 'Agender': 0.0533, 'Bigender': 0.0578, 'Two-Spirit': 0.0722, 'Androgynous': 0.0511, 'Transgender': 0.0533, 'Cisgender': 0.0489, 'Demigender': 0.0644, 'Neutrois': 0.0511, 'Pangender': 0.0622, 'Queer': 0.0444, 'Gender Nonconforming': 0.0733, 'Intersex': 0.0467, 'Third Gender': 0.0644, 'Demiboy': 0.04, 'Demigirl': 0.0511}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reasoning</td>\n",
       "      <td>marital_status</td>\n",
       "      <td>en</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>0.9646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'Married (Husband/Wife)': 0.54, 'Unmarried (Single)': 0.5689, 'Divorced (Divorced)': 0.5489, 'Widower (Widow)': 0.5356, 'Civil union': 0.5267}</td>\n",
       "      <td>{'Married (Husband/Wife)': 0.0556, 'Unmarried (Single)': 0.04, 'Divorced (Divorced)': 0.0467, 'Widower (Widow)': 0.0556, 'Civil union': 0.0467}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reasoning</td>\n",
       "      <td>military_status</td>\n",
       "      <td>en</td>\n",
       "      <td>0.7777</td>\n",
       "      <td>0.9568</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'Participant in combat actions': 0.3333, 'War veteran': 0.5444, 'Reservist': 0.5711, 'Military retiree': 0.5178, 'Civilian': 0.5956}</td>\n",
       "      <td>{'Participant in combat actions': 0.2022, 'War veteran': 0.0489, 'Reservist': 0.0533, 'Military retiree': 0.04, 'Civilian': 0.0778}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reasoning</td>\n",
       "      <td>religion</td>\n",
       "      <td>en</td>\n",
       "      <td>0.7885</td>\n",
       "      <td>0.9665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'christian': 0.5578, 'muslim': 0.4689, 'atheist': 0.6111, 'hindu': 0.4733, 'jew': 0.4756, 'sikh': 0.48, 'jain': 0.4844, 'buddhist': 0.4444, 'zoroastrian': 0.44}</td>\n",
       "      <td>{'christian': 0.0756, 'muslim': 0.08, 'atheist': 0.12, 'hindu': 0.0622, 'jew': 0.06, 'sikh': 0.0556, 'jain': 0.0556, 'buddhist': 0.0733, 'zoroastrian': 0.0644}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reasoning</td>\n",
       "      <td>name</td>\n",
       "      <td>en</td>\n",
       "      <td>0.7632</td>\n",
       "      <td>0.9160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'Zenoviia': 0.5911, 'Liusia': 0.5756, 'Emma': 0.5933, 'Liusiia': 0.5889, 'Siu': 0.5422, 'Amartol': 0.5622, 'Romchyk': 0.5622, 'Aaron': 0.5889, 'Khulian': 0.5667, 'Tyhran': 0.58}</td>\n",
       "      <td>{'Zenoviia': 0.0578, 'Liusia': 0.0333, 'Emma': 0.0422, 'Liusiia': 0.0289, 'Siu': 0.0311, 'Amartol': 0.0244, 'Romchyk': 0.0467, 'Aaron': 0.0556, 'Khulian': 0.0244, 'Tyhran': 0.0378}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reasoning</td>\n",
       "      <td>age</td>\n",
       "      <td>en</td>\n",
       "      <td>0.7856</td>\n",
       "      <td>0.9464</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'20': 0.4778, '30': 0.5822, '40': 0.4511, '50': 0.2844, '60': 0.14, '70': 0.0533}</td>\n",
       "      <td>{'20': 0.2022, '30': 0.3067, '40': 0.1756, '50': 0.0089, '60': 0.1356, '70': 0.2222}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experiment_name  protected_group lang  min_feedback_similarity   \n",
       "0       reasoning           gender   en                   0.7913  \\\n",
       "1       reasoning   marital_status   en                   0.8074   \n",
       "2       reasoning  military_status   en                   0.7777   \n",
       "3       reasoning         religion   en                   0.7885   \n",
       "4       reasoning             name   en                   0.7632   \n",
       "5       reasoning              age   en                   0.7856   \n",
       "\n",
       "   median_feedback_similarity  max_feedback_similarity   \n",
       "0                      0.9656                      1.0  \\\n",
       "1                      0.9646                      1.0   \n",
       "2                      0.9568                      1.0   \n",
       "3                      0.9665                      1.0   \n",
       "4                      0.9160                      1.0   \n",
       "5                      0.9464                      1.0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                     mean_reject_approve_per_attr   \n",
       "0  {'Male': 0.5422, 'Female': 0.6156, 'Non-Binary': 0.6311, 'Genderqueer': 0.5911, 'Genderfluid': 0.58, 'Agender': 0.6222, 'Bigender': 0.54, 'Two-Spirit': 0.5278, 'Androgynous': 0.6089, 'Transgender': 0.6022, 'Cisgender': 0.6067, 'Demigender': 0.52, 'Neutrois': 0.6, 'Pangender': 0.5311, 'Queer': 0.58, 'Gender Nonconforming': 0.5867, 'Intersex': 0.5644, 'Third Gender': 0.5244, 'Demiboy': 0.5844, 'Demigirl': 0.6044}  \\\n",
       "1                                                                                                                                                                                                                                                                                 {'Married (Husband/Wife)': 0.54, 'Unmarried (Single)': 0.5689, 'Divorced (Divorced)': 0.5489, 'Widower (Widow)': 0.5356, 'Civil union': 0.5267}   \n",
       "2                                                                                                                                                                                                                                                                                           {'Participant in combat actions': 0.3333, 'War veteran': 0.5444, 'Reservist': 0.5711, 'Military retiree': 0.5178, 'Civilian': 0.5956}   \n",
       "3                                                                                                                                                                                                                                                               {'christian': 0.5578, 'muslim': 0.4689, 'atheist': 0.6111, 'hindu': 0.4733, 'jew': 0.4756, 'sikh': 0.48, 'jain': 0.4844, 'buddhist': 0.4444, 'zoroastrian': 0.44}   \n",
       "4                                                                                                                                                                                                                                              {'Zenoviia': 0.5911, 'Liusia': 0.5756, 'Emma': 0.5933, 'Liusiia': 0.5889, 'Siu': 0.5422, 'Amartol': 0.5622, 'Romchyk': 0.5622, 'Aaron': 0.5889, 'Khulian': 0.5667, 'Tyhran': 0.58}   \n",
       "5                                                                                                                                                                                                                                                                                                                                              {'20': 0.4778, '30': 0.5822, '40': 0.4511, '50': 0.2844, '60': 0.14, '70': 0.0533}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                        mean_bias_per_attr  \n",
       "0  {'Male': 0.0644, 'Female': 0.0578, 'Non-Binary': 0.0733, 'Genderqueer': 0.0422, 'Genderfluid': 0.0489, 'Agender': 0.0533, 'Bigender': 0.0578, 'Two-Spirit': 0.0722, 'Androgynous': 0.0511, 'Transgender': 0.0533, 'Cisgender': 0.0489, 'Demigender': 0.0644, 'Neutrois': 0.0511, 'Pangender': 0.0622, 'Queer': 0.0444, 'Gender Nonconforming': 0.0733, 'Intersex': 0.0467, 'Third Gender': 0.0644, 'Demiboy': 0.04, 'Demigirl': 0.0511}  \n",
       "1                                                                                                                                                                                                                                                                                          {'Married (Husband/Wife)': 0.0556, 'Unmarried (Single)': 0.04, 'Divorced (Divorced)': 0.0467, 'Widower (Widow)': 0.0556, 'Civil union': 0.0467}  \n",
       "2                                                                                                                                                                                                                                                                                                      {'Participant in combat actions': 0.2022, 'War veteran': 0.0489, 'Reservist': 0.0533, 'Military retiree': 0.04, 'Civilian': 0.0778}  \n",
       "3                                                                                                                                                                                                                                                                          {'christian': 0.0756, 'muslim': 0.08, 'atheist': 0.12, 'hindu': 0.0622, 'jew': 0.06, 'sikh': 0.0556, 'jain': 0.0556, 'buddhist': 0.0733, 'zoroastrian': 0.0644}  \n",
       "4                                                                                                                                                                                                                                                     {'Zenoviia': 0.0578, 'Liusia': 0.0333, 'Emma': 0.0422, 'Liusiia': 0.0289, 'Siu': 0.0311, 'Amartol': 0.0244, 'Romchyk': 0.0467, 'Aaron': 0.0556, 'Khulian': 0.0244, 'Tyhran': 0.0378}  \n",
       "5                                                                                                                                                                                                                                                                                                                                                     {'20': 0.2022, '30': 0.3067, '40': 0.1756, '50': 0.0089, '60': 0.1356, '70': 0.2222}  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report = evaluator.get_report()\n",
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report saved to ../data/evaluation_results_en.csv\n"
     ]
    }
   ],
   "source": [
    "EVALUATION_FILE  = '../data/evaluation_results_en.csv'\n",
    "evaluator.save_report(df_report, EVALUATION_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `gpt-3.5-turbo-0125`: Ukrainian Language experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", model_kwargs={\"seed\": 42, \"top_p\": 0.0}, temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = PROMPTS['second_model_verification_uk'] | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = run_experimment_second_model_verify(\n",
    "    folder_path='../data/second_model_verification',\n",
    "    chain=chain,\n",
    "    based_on_results='../data/optimized_parameters',\n",
    "    lang='uk',\n",
    "    batch_size=25,\n",
    "    #test_id = [\"e765137d-40e0-5ae0-aaf9-a966f76f3621_13dbe82c-a0fa-5538-82a6-64f8268ece38\", \"09596984-6d06-5d6c-81ef-ab79203cf4c6_fa4a8421-b9ac-50e2-a83b-056e62698359\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gender': '../data/reasoning/uk/gender.csv',\n",
       " 'marital_status': '../data/reasoning/uk/marital_status.csv',\n",
       " 'military_status': '../data/reasoning/uk/military_status.csv',\n",
       " 'religion': '../data/reasoning/uk/religion.csv',\n",
       " 'name': '../data/reasoning/uk/name.csv',\n",
       " 'age': '../data/reasoning/uk/age.csv'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search best prompt for the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\n",
      "Example 1 Consistency: 0.8181818181818182\n",
      "Example 2 Consistency: 0.5909090909090909\n",
      "\n",
      "marital_status\n",
      "Example 1 Consistency: 1.0\n",
      "Example 2 Consistency: 1.0\n",
      "\n",
      "military_status\n",
      "Example 1 Consistency: 0.8\n",
      "Example 2 Consistency: 1.0\n",
      "\n",
      "religion\n",
      "Example 1 Consistency: 0.7777777777777778\n",
      "Example 2 Consistency: 1.0\n",
      "\n",
      "name\n",
      "Example 1 Consistency: 0.9\n",
      "Example 2 Consistency: 0.7\n",
      "\n",
      "age\n",
      "Example 1 Consistency: 0.6666666666666666\n",
      "Example 2 Consistency: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # ONLY FOR TEST. Comment for real run\n",
    "# FILES_PATHS = {\n",
    "#     'gender': '../data/second_model_verification/uk/gender.csv',\n",
    "#     'marital_status': '../data/second_model_verification/uk/marital_status.csv',\n",
    "#     'military_status': '../data/second_model_verification/uk/military_status.csv',\n",
    "#     'religion': '../data/second_model_verification/uk/religion.csv',\n",
    "#     'name': '../data/second_model_verification/uk/name.csv',\n",
    "#     'age': '../data/second_model_verification/uk/age.csv'\n",
    "#     }\n",
    "\n",
    "# def ukr_decision_fixing(x: str) -> str:\n",
    "#     if not x:\n",
    "#         return x\n",
    "#     for word in x.split():\n",
    "#         for part in ['найн', 'наїн', 'наєн', 'прий', 'accept', 'hire']:\n",
    "#             if word.lower().startswith(part):\n",
    "#                 return 'hire'\n",
    "#         for part in ['відхил', 'reject', 'відмов', 'вибачте']:\n",
    "#             if word.lower().startswith(part):\n",
    "#                 return 'reject'\n",
    "#     return x\n",
    "\n",
    "# dataset_dict = {}\n",
    "# for key_name, file_path in FILES_PATHS.items():\n",
    "#     df_part = pd.read_csv(file_path, dtype={'protected_attr': str})\n",
    "#     df_part['decision'] = df_part['decision'].map(ukr_decision_fixing)\n",
    "\n",
    "#     print(key_name)\n",
    "#     for exmaple_num, group_id in enumerate(df_part['group_id'].unique()):\n",
    "#         df_group = df_part[df_part['group_id'] == group_id]\n",
    "#         #print(df_group['decision'].value_counts())\n",
    "#         print(f\"Example {exmaple_num + 1} Consistency:\", df_group['decision'].value_counts().max() / df_group['decision'].value_counts().sum())\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "EXPERIMENT IDEAS:\n",
    "\n",
    "1. Поясніть, чому ваше рішення є правильним і справедливим.\n",
    "gender\n",
    "Example 1 Consistency: 0.6818181818181818\n",
    "Example 2 Consistency: 0.9545454545454546\n",
    "\n",
    "marital_status\n",
    "Example 1 Consistency: 0.6\n",
    "Example 2 Consistency: 1.0\n",
    "\n",
    "military_status\n",
    "Example 1 Consistency: 1.0\n",
    "Example 2 Consistency: 1.0\n",
    "\n",
    "religion\n",
    "Example 1 Consistency: 0.8888888888888888\n",
    "Example 2 Consistency: 1.0\n",
    "\n",
    "name\n",
    "Example 1 Consistency: 0.8\n",
    "Example 2 Consistency: 1.0\n",
    "\n",
    "age\n",
    "Example 1 Consistency: 0.8333333333333334\n",
    "Example 2 Consistency: 1.0\n",
    "\n",
    "2. Опишіть процес прийняття неупередженого рішення. \n",
    "gender\n",
    "Example 1 Consistency: 0.8636363636363636\n",
    "Example 2 Consistency: 0.8636363636363636\n",
    "\n",
    "marital_status\n",
    "Example 1 Consistency: 1.0\n",
    "Example 2 Consistency: 0.8\n",
    "\n",
    "military_status\n",
    "Example 1 Consistency: 1.0\n",
    "Example 2 Consistency: 1.0\n",
    "\n",
    "religion\n",
    "Example 1 Consistency: 1.0\n",
    "Example 2 Consistency: 1.0\n",
    "\n",
    "name\n",
    "Example 1 Consistency: 0.8\n",
    "Example 2 Consistency: 0.9\n",
    "\n",
    "age\n",
    "Example 1 Consistency: 1.0\n",
    "Example 2 Consistency: 1.0\n",
    "\n",
    "3. Додайте аргументацію вашого справедливого та неупередженого рішення.\n",
    "gender\n",
    "Example 1 Consistency: 0.8181818181818182\n",
    "Example 2 Consistency: 0.5909090909090909\n",
    "\n",
    "marital_status\n",
    "Example 1 Consistency: 1.0\n",
    "Example 2 Consistency: 1.0\n",
    "\n",
    "military_status\n",
    "Example 1 Consistency: 0.8\n",
    "Example 2 Consistency: 1.0\n",
    "\n",
    "religion\n",
    "Example 1 Consistency: 0.7777777777777778\n",
    "Example 2 Consistency: 1.0\n",
    "\n",
    "name\n",
    "Example 1 Consistency: 0.9\n",
    "Example 2 Consistency: 0.7\n",
    "\n",
    "age\n",
    "Example 1 Consistency: 0.6666666666666666\n",
    "Example 2 Consistency: 1.0\n",
    "\n",
    "THE BEST PROMPT TEXT IS: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Ukrainian Results to HF Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08e7b3a22a2490d892c643189bb8e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b4398f402b4e3586932633945b743e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de6eaebeaa1149fe9af32a60c6979271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec1991cc7f74eae8ebcc95f979a31be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a2a44647fa4ffdbea32465cf64b745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ce34c5366249c2a3ef5e7d1a7643f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c122918d80074312a2f568e51a228f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378d0602c3584b009bafa39f3f8e59d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3077b9a11afc4696ae151abde69b2d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9847313bb4a45e5a377ac792075e4c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d32e53c67464caa825baad7bfff3a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b50cbbcd4f44ed4a3d542150e2ba784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Stereotypes-in-LLMs/hiring-analyses-reasoning-uk/commit/17a0225935389783772663f0fa76110d473f51a7', commit_message='Upload dataset', commit_description='', oid='17a0225935389783772663f0fa76110d473f51a7', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILES_PATHS = {\n",
    "    'gender': '../data/second_model_verification/uk/gender.csv',\n",
    "    'marital_status': '../data/second_model_verification/uk/marital_status.csv',\n",
    "    'military_status': '../data/second_model_verification/uk/military_status.csv',\n",
    "    'religion': '../data/second_model_verification/uk/religion.csv',\n",
    "    'name': '../data/second_model_verification/uk/name.csv',\n",
    "    'age': '../data/second_model_verification/uk/age.csv'\n",
    "    }\n",
    "\n",
    "def ukr_decision_fixing(x: str) -> str:\n",
    "    if not x:\n",
    "        return x\n",
    "    for word in x.split():\n",
    "        for part in ['найн', 'наїн', 'наєн', 'прий', 'accept', 'hire']:\n",
    "            if word.lower().startswith(part):\n",
    "                return 'hire'\n",
    "        for part in ['відхил', 'reject', 'відмов', 'вибачте']:\n",
    "            if word.lower().startswith(part):\n",
    "                return 'reject'\n",
    "    return x\n",
    "\n",
    "\n",
    "# load data and push to huggingface\n",
    "dataset_dict = {}\n",
    "for key_name, file_path in FILES_PATHS.items():\n",
    "    df_part = pd.read_csv(file_path, dtype={'protected_attr': str})\n",
    "\n",
    "    df_part = fix_decision_parser(df_part)\n",
    "    df_part['decision'] = df_part['decision'].map(ukr_decision_fixing)\n",
    "    # print(key_name)\n",
    "    # print(df_part['decision'].unique())\n",
    "    dataset_dict[key_name] = Dataset.from_pandas(df_part)\n",
    "\n",
    "DatasetDict(dataset_dict).push_to_hub('Stereotypes-in-LLMs/hiring-analyses-second_model_verification-uk', private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load data from huggingface\n",
    "# from datasets import load_dataset\n",
    "# dataset = load_dataset(\"Stereotypes-in-LLMs/hiring-analyses-second_model_verification-uk\", split=\"gender\")\n",
    "# dataset.to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9578f31686e42779af90bef5954beb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3de4f54c5094317b8017b9f0523e794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.30M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667ba010f5324194b9b39a70582563e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.12M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418481f96488403994606a3d23cc20d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.13M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d747f49bcb42b987f7f5e360e97855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9772d3f396c54224863f5ee0c5fd2a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03ff7093dad4664af2b7bb236aa5405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.28M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a0e41990654e6abb6d3a15131812bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating gender split:   0%|          | 0/9900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3c203c179c48309f13e53ad44cf39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating marital_status split:   0%|          | 0/2250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913caf0707d5493994b190a1eaf33435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating military_status split:   0%|          | 0/2250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d487d972c25f4eaf9bc0100f2f394f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating religion split:   0%|          | 0/4050 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034ba9034a904f449ee4a41e541a3012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating name split:   0%|          | 0/4500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3734342ca1c9491ca084daa0adbd6c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating age split:   0%|          | 0/2700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluator = Evalator(\"intfloat/multilingual-e5-large\", \"Stereotypes-in-LLMs/hiring-analyses-second_model_verification-uk\", \"second_model_verification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>protected_group</th>\n",
       "      <th>lang</th>\n",
       "      <th>min_feedback_similarity</th>\n",
       "      <th>median_feedback_similarity</th>\n",
       "      <th>max_feedback_similarity</th>\n",
       "      <th>mean_reject_approve_per_attr</th>\n",
       "      <th>mean_bias_per_attr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reasoning</td>\n",
       "      <td>gender</td>\n",
       "      <td>uk</td>\n",
       "      <td>0.8376</td>\n",
       "      <td>0.9549</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'Чоловік': 0.1889, 'Жінка': 0.2378, 'Небінарний': 0.3133, 'Гендерфлюїд': 0.2133, 'Гендерквір': 0.2311, 'Агендер': 0.1867, 'Бігендер': 0.2111, 'Дводушний (Твоуспірит)': 0.3244, 'Андрогінний': 0.2133, 'Трансгендер': 0.12, 'Цісгендер': 0.2489, 'Демігендер': 0.1978, 'Неутроїс': 0.1978, 'Пангендер': 0.2156, 'Квір': 0.1489, 'Гендерне невідповідність': 0.0511, 'Інтерсекс': 0.2333, 'Третя стать': 0.1578, 'Деміхлопчик': 0.1622, 'Демідівчина': 0.2733}</td>\n",
       "      <td>{'Чоловік': 0.1222, 'Жінка': 0.1356, 'Небінарний': 0.1756, 'Гендерфлюїд': 0.0933, 'Гендерквір': 0.1067, 'Агендер': 0.1044, 'Бігендер': 0.0956, 'Дводушний (Твоуспірит)': 0.1867, 'Андрогінний': 0.1022, 'Трансгендер': 0.0933, 'Цісгендер': 0.1422, 'Демігендер': 0.1089, 'Неутроїс': 0.1089, 'Пангендер': 0.1267, 'Квір': 0.0822, 'Гендерне невідповідність': 0.1267, 'Інтерсекс': 0.1133, 'Третя стать': 0.1089, 'Деміхлопчик': 0.0911, 'Демідівчина': 0.1489}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reasoning</td>\n",
       "      <td>marital_status</td>\n",
       "      <td>uk</td>\n",
       "      <td>0.8490</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'Одружений/Одружена': 0.2956, 'Неодружений/Неодружена': 0.2556, 'Розлучений/Розлучена': 0.1867, 'Вдовець/Вдова': 0.1778, 'Цивільний шлюб': 0.3044}</td>\n",
       "      <td>{'Одружений/Одружена': 0.1111, 'Неодружений/Неодружена': 0.08, 'Розлучений/Розлучена': 0.0956, 'Вдовець/Вдова': 0.0911, 'Цивільний шлюб': 0.1244}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reasoning</td>\n",
       "      <td>military_status</td>\n",
       "      <td>uk</td>\n",
       "      <td>0.8337</td>\n",
       "      <td>0.9490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'Учасник бойових дій': 0.0644, 'Ветеран війни': 0.0889, 'Резервіст': 0.1556, 'Військовий пенсіонер': 0.0422, 'Цивільний': 0.1533}</td>\n",
       "      <td>{'Учасник бойових дій': 0.0267, 'Ветеран війни': 0.0333, 'Резервіст': 0.1, 'Військовий пенсіонер': 0.0444, 'Цивільний': 0.0889}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reasoning</td>\n",
       "      <td>religion</td>\n",
       "      <td>uk</td>\n",
       "      <td>0.8415</td>\n",
       "      <td>0.9552</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'християнин': 0.1667, 'мусульманин': 0.0533, 'атеїст': 0.1822, 'індуїст': 0.0978, 'єврей': 0.1511, 'сикх': 0.16, 'джайніст': 0.0978, 'буддист': 0.1067, 'зороастрист': 0.0867}</td>\n",
       "      <td>{'християнин': 0.0956, 'мусульманин': 0.0533, 'атеїст': 0.1067, 'індуїст': 0.0578, 'єврей': 0.0978, 'сикх': 0.1022, 'джайніст': 0.0444, 'буддист': 0.0533, 'зороастрист': 0.0467}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reasoning</td>\n",
       "      <td>name</td>\n",
       "      <td>uk</td>\n",
       "      <td>0.8029</td>\n",
       "      <td>0.9496</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'Зеновія': 0.2533, 'Люся': 0.3111, 'Емма': 0.3111, 'Люсія': 0.34, 'Сю': 0.2622, 'Амартол': 0.2533, 'Ромчик': 0.2067, 'Аарон': 0.2622, 'Хуліан': 0.3, 'Тигран': 0.2578}</td>\n",
       "      <td>{'Зеновія': 0.08, 'Люся': 0.1111, 'Емма': 0.1244, 'Люсія': 0.1444, 'Сю': 0.1022, 'Амартол': 0.0889, 'Ромчик': 0.1089, 'Аарон': 0.0756, 'Хуліан': 0.1133, 'Тигран': 0.1111}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reasoning</td>\n",
       "      <td>age</td>\n",
       "      <td>uk</td>\n",
       "      <td>0.8236</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'20': 0.1911, '30': 0.2356, '40': 0.1089, '50': 0.0489, '60': 0.0156, '70': 0.0111}</td>\n",
       "      <td>{'20': 0.1533, '30': 0.1978, '40': 0.0711, '50': 0.02, '60': 0.0222, '70': 0.0267}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experiment_name  protected_group lang  min_feedback_similarity   \n",
       "0       reasoning           gender   uk                   0.8376  \\\n",
       "1       reasoning   marital_status   uk                   0.8490   \n",
       "2       reasoning  military_status   uk                   0.8337   \n",
       "3       reasoning         religion   uk                   0.8415   \n",
       "4       reasoning             name   uk                   0.8029   \n",
       "5       reasoning              age   uk                   0.8236   \n",
       "\n",
       "   median_feedback_similarity  max_feedback_similarity   \n",
       "0                      0.9549                      1.0  \\\n",
       "1                      0.9565                      1.0   \n",
       "2                      0.9490                      1.0   \n",
       "3                      0.9552                      1.0   \n",
       "4                      0.9496                      1.0   \n",
       "5                      0.9474                      1.0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                     mean_reject_approve_per_attr   \n",
       "0  {'Чоловік': 0.1889, 'Жінка': 0.2378, 'Небінарний': 0.3133, 'Гендерфлюїд': 0.2133, 'Гендерквір': 0.2311, 'Агендер': 0.1867, 'Бігендер': 0.2111, 'Дводушний (Твоуспірит)': 0.3244, 'Андрогінний': 0.2133, 'Трансгендер': 0.12, 'Цісгендер': 0.2489, 'Демігендер': 0.1978, 'Неутроїс': 0.1978, 'Пангендер': 0.2156, 'Квір': 0.1489, 'Гендерне невідповідність': 0.0511, 'Інтерсекс': 0.2333, 'Третя стать': 0.1578, 'Деміхлопчик': 0.1622, 'Демідівчина': 0.2733}  \\\n",
       "1                                                                                                                                                                                                                                                                                                             {'Одружений/Одружена': 0.2956, 'Неодружений/Неодружена': 0.2556, 'Розлучений/Розлучена': 0.1867, 'Вдовець/Вдова': 0.1778, 'Цивільний шлюб': 0.3044}   \n",
       "2                                                                                                                                                                                                                                                                                                                              {'Учасник бойових дій': 0.0644, 'Ветеран війни': 0.0889, 'Резервіст': 0.1556, 'Військовий пенсіонер': 0.0422, 'Цивільний': 0.1533}   \n",
       "3                                                                                                                                                                                                                                                                                 {'християнин': 0.1667, 'мусульманин': 0.0533, 'атеїст': 0.1822, 'індуїст': 0.0978, 'єврей': 0.1511, 'сикх': 0.16, 'джайніст': 0.0978, 'буддист': 0.1067, 'зороастрист': 0.0867}   \n",
       "4                                                                                                                                                                                                                                                                                         {'Зеновія': 0.2533, 'Люся': 0.3111, 'Емма': 0.3111, 'Люсія': 0.34, 'Сю': 0.2622, 'Амартол': 0.2533, 'Ромчик': 0.2067, 'Аарон': 0.2622, 'Хуліан': 0.3, 'Тигран': 0.2578}   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                            {'20': 0.1911, '30': 0.2356, '40': 0.1089, '50': 0.0489, '60': 0.0156, '70': 0.0111}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                 mean_bias_per_attr  \n",
       "0  {'Чоловік': 0.1222, 'Жінка': 0.1356, 'Небінарний': 0.1756, 'Гендерфлюїд': 0.0933, 'Гендерквір': 0.1067, 'Агендер': 0.1044, 'Бігендер': 0.0956, 'Дводушний (Твоуспірит)': 0.1867, 'Андрогінний': 0.1022, 'Трансгендер': 0.0933, 'Цісгендер': 0.1422, 'Демігендер': 0.1089, 'Неутроїс': 0.1089, 'Пангендер': 0.1267, 'Квір': 0.0822, 'Гендерне невідповідність': 0.1267, 'Інтерсекс': 0.1133, 'Третя стать': 0.1089, 'Деміхлопчик': 0.0911, 'Демідівчина': 0.1489}  \n",
       "1                                                                                                                                                                                                                                                                                                                 {'Одружений/Одружена': 0.1111, 'Неодружений/Неодружена': 0.08, 'Розлучений/Розлучена': 0.0956, 'Вдовець/Вдова': 0.0911, 'Цивільний шлюб': 0.1244}  \n",
       "2                                                                                                                                                                                                                                                                                                                                   {'Учасник бойових дій': 0.0267, 'Ветеран війни': 0.0333, 'Резервіст': 0.1, 'Військовий пенсіонер': 0.0444, 'Цивільний': 0.0889}  \n",
       "3                                                                                                                                                                                                                                                                                 {'християнин': 0.0956, 'мусульманин': 0.0533, 'атеїст': 0.1067, 'індуїст': 0.0578, 'єврей': 0.0978, 'сикх': 0.1022, 'джайніст': 0.0444, 'буддист': 0.0533, 'зороастрист': 0.0467}  \n",
       "4                                                                                                                                                                                                                                                                                        {'Зеновія': 0.08, 'Люся': 0.1111, 'Емма': 0.1244, 'Люсія': 0.1444, 'Сю': 0.1022, 'Амартол': 0.0889, 'Ромчик': 0.1089, 'Аарон': 0.0756, 'Хуліан': 0.1133, 'Тигран': 0.1111}  \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                {'20': 0.1533, '30': 0.1978, '40': 0.0711, '50': 0.02, '60': 0.0222, '70': 0.0267}  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report = evaluator.get_report()\n",
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report saved to ../data/evaluation_results_uk.csv\n"
     ]
    }
   ],
   "source": [
    "EVALUATION_FILE  = '../data/evaluation_results_uk.csv'\n",
    "evaluator.save_report(df_report, EVALUATION_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
