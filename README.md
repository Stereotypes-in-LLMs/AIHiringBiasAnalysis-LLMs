# Analysis of LLMs Stereotypes for AI Assisted Hiring Decision

This repository contains code and resources for analyzing stereotypes in Large Language Models (LLMs) for AI-assisted hiring decisions. The project focuses on data injection, fairness evaluation, and mitigation techniques to address biases in hiring processes for English and Ukrainian languages.

## Notebooks
The `notebooks` directory contains the following notebooks:

- Notebook presenting the baseline analysis of stereotypes in LLMs for AI-assisted hiring decisions.
- Notebooks presenting various mitigation techniques for addressing biases in LLMs.
- Notebook presenting the analysis of results obtained from fairness evaluation and mitigation techniques.
- etc.

## Protected Groups
The `protected_groups` directory contains information about all the protected groups and their attributes for which we conducted our research. This includes data related to gender, marital, military statuses, etc. in English and Ukrainian languages.

## Contributors
- [Stereotypes-in-LLMs](https://github.com/Stereotypes-in-LLMs)

## License
This project is licensed under the [Apache License 2.0](LICENSE).
